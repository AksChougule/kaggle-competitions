{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this note bookbook, we will make a few changes to the workflow by referring to the one of the available kernels.\n",
    "\n",
    "Planned Changes:\n",
    "- Create and save images by reading parquet\n",
    "- Istead of convering grayscale into 3-channel, we will modify the architecture to accomodate 1-channel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# If we don't do this then image will open as pop-up and not in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9126408\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 4161805187 Jan 16 23:18 bengaliai-cv19.zip\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu       4830 Dec 19 18:22 class_map.csv\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu        944 Dec 19 18:22 sample_submission.csv\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu       1742 Dec 19 18:22 test.csv\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu    9903859 Dec 19 18:22 test_image_data_0.parquet\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu   10003997 Dec 19 18:22 test_image_data_1.parquet\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu    9996850 Dec 19 18:22 test_image_data_2.parquet\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu    9995989 Dec 19 18:22 test_image_data_3.parquet\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu    6281787 Dec 19 18:22 train.csv\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 1285682162 Dec 19 18:22 train_image_data_0.parquet\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 1278647926 Dec 19 18:25 train_image_data_1.parquet\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 1287469785 Dec 19 18:29 train_image_data_2.parquet\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu 1285595675 Dec 19 18:32 train_image_data_3.parquet\r\n",
      "drwxr-xr-x 8 ubuntu ubuntu       4096 Jan 21 23:11 training_images\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/datasets/bengali-ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Mapping File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = pd.read_csv(\"/home/ubuntu/datasets/bengali-ai/class_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of           component_type  label component\n",
       "0          grapheme_root      0         ং\n",
       "1          grapheme_root      1         ঃ\n",
       "2          grapheme_root      2         অ\n",
       "3          grapheme_root      3         আ\n",
       "4          grapheme_root      4         ই\n",
       "5          grapheme_root      5         ঈ\n",
       "6          grapheme_root      6         উ\n",
       "7          grapheme_root      7         ঊ\n",
       "8          grapheme_root      8         ঋ\n",
       "9          grapheme_root      9         এ\n",
       "10         grapheme_root     10         ঐ\n",
       "11         grapheme_root     11         ও\n",
       "12         grapheme_root     12         ঔ\n",
       "13         grapheme_root     13         ক\n",
       "14         grapheme_root     14       ক্ক\n",
       "15         grapheme_root     15       ক্ট\n",
       "16         grapheme_root     16       ক্ত\n",
       "17         grapheme_root     17       ক্ল\n",
       "18         grapheme_root     18       ক্ষ\n",
       "19         grapheme_root     19     ক্ষ্ণ\n",
       "20         grapheme_root     20     ক্ষ্ম\n",
       "21         grapheme_root     21       ক্স\n",
       "22         grapheme_root     22         খ\n",
       "23         grapheme_root     23         গ\n",
       "24         grapheme_root     24       গ্ধ\n",
       "25         grapheme_root     25       গ্ন\n",
       "26         grapheme_root     26       গ্ব\n",
       "27         grapheme_root     27       গ্ম\n",
       "28         grapheme_root     28       গ্ল\n",
       "29         grapheme_root     29         ঘ\n",
       "..                   ...    ...       ...\n",
       "156        grapheme_root    156       স্ম\n",
       "157        grapheme_root    157       স্ল\n",
       "158        grapheme_root    158       স্স\n",
       "159        grapheme_root    159         হ\n",
       "160        grapheme_root    160       হ্ন\n",
       "161        grapheme_root    161       হ্ব\n",
       "162        grapheme_root    162       হ্ম\n",
       "163        grapheme_root    163       হ্ল\n",
       "164        grapheme_root    164         ৎ\n",
       "165        grapheme_root    165         ড়\n",
       "166        grapheme_root    166         ঢ়\n",
       "167        grapheme_root    167         য়\n",
       "168      vowel_diacritic      0         0\n",
       "169      vowel_diacritic      1         া\n",
       "170      vowel_diacritic      2         ি\n",
       "171      vowel_diacritic      3         ী\n",
       "172      vowel_diacritic      4         ু\n",
       "173      vowel_diacritic      5         ূ\n",
       "174      vowel_diacritic      6         ৃ\n",
       "175      vowel_diacritic      7         ে\n",
       "176      vowel_diacritic      8         ৈ\n",
       "177      vowel_diacritic      9         ো\n",
       "178      vowel_diacritic     10         ৌ\n",
       "179  consonant_diacritic      0         0\n",
       "180  consonant_diacritic      1         ঁ\n",
       "181  consonant_diacritic      2        র্\n",
       "182  consonant_diacritic      3       র্য\n",
       "183  consonant_diacritic      4        ্য\n",
       "184  consonant_diacritic      5        ্র\n",
       "185  consonant_diacritic      6      ্র্য\n",
       "\n",
       "[186 rows x 3 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_type</th>\n",
       "      <th>label</th>\n",
       "      <th>component</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>0</td>\n",
       "      <td>ং</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>1</td>\n",
       "      <td>ঃ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>2</td>\n",
       "      <td>অ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>3</td>\n",
       "      <td>আ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>4</td>\n",
       "      <td>ই</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>5</td>\n",
       "      <td>ঈ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>6</td>\n",
       "      <td>উ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>7</td>\n",
       "      <td>ঊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>8</td>\n",
       "      <td>ঋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grapheme_root</td>\n",
       "      <td>9</td>\n",
       "      <td>এ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  component_type  label component\n",
       "0  grapheme_root      0         ং\n",
       "1  grapheme_root      1         ঃ\n",
       "2  grapheme_root      2         অ\n",
       "3  grapheme_root      3         আ\n",
       "4  grapheme_root      4         ই\n",
       "5  grapheme_root      5         ঈ\n",
       "6  grapheme_root      6         উ\n",
       "7  grapheme_root      7         ঊ\n",
       "8  grapheme_root      8         ঋ\n",
       "9  grapheme_root      9         এ"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training label files\n",
    "train_labels = pd.read_csv(\"/home/ubuntu/datasets/bengali-ai/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200840, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167,\n",
       " 0,\n",
       " array([ 15, 159,  22,  53,  71, 153,  52, 139,  67,  64, 115, 107,  74,\n",
       "        100,  48,  72,  13,  79, 109,  23,  42,  60, 142,  61, 147,  81,\n",
       "        148, 160,  58,  99, 103,  44, 167, 120,  62, 151,  32, 125,  38,\n",
       "        127,  24, 124,  96,  43, 132, 149, 123,  54,  19,  87,  35,  83,\n",
       "         97,  77, 165,  92, 133, 118,  85,  56,  95, 136, 138, 106,  86,\n",
       "         29,  39, 122,  65,  30,  76,  16,  68, 110,  46, 105, 155, 129,\n",
       "         25,  59,  36,  70, 152,  18,  89, 128, 113, 144,  49, 117, 154,\n",
       "         31,   6,  26, 150,  40, 111,  55,   1, 119, 140,  66,  28,  14,\n",
       "        164,  27, 121, 156,  63,  84, 137,  98, 143,  47, 135,  75, 141,\n",
       "         88, 116,  91,  45,  69,  94,  93, 131, 146, 134, 112, 108,   9,\n",
       "         80,   3, 166,  41,  17, 162,  21, 158,  10,  51, 101,  82,  57,\n",
       "          4,   5,  90,  20,   2, 102, 126,  33, 161,  34,  50,   7, 163,\n",
       "         78,  73, 145, 130,   0, 104,   8,  37,  11, 157, 114,  12]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels['grapheme_root'].max(), train_labels['grapheme_root'].min(), train_labels['grapheme_root'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch databuild libraries and modules\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliCharacterDataset(Dataset):\n",
    "    \"\"\"Bengali language handwritten character dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (string): Dataframe of parquet dataset with image data.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):        \n",
    "        return len(os.listdir(self.root_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_id = 'Train_'+str(idx)\n",
    "        img_name = image_id+'.png'\n",
    "        \n",
    "        # columns from class_map: image_id, grapheme_root, vowel_diacritic, consonant_diacritic, grapheme\n",
    "        img_label = train_labels.loc[train_labels['image_id'] == image_id, 'grapheme_root'].to_numpy()[0] \n",
    "        # added to.numpy()[0] to remove index number\n",
    "                \n",
    "        img_path = os.path.join(self.root_dir,img_name)\n",
    "        image = io.imread(img_path)\n",
    "\n",
    "        # sample = {'image': img_data, 'img_label': img_label}\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(im.fromarray(image).convert('RGB'))\n",
    "            # sample = {'img_label': img_label, 'image': img_data}\n",
    "\n",
    "        return image, img_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create a PyTorch Dataset object with transformations\n",
    "transformed_dataset = BengaliCharacterDataset(root_dir='/home/ubuntu/datasets/bengali-ai/training_images/train_224by224/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                               transforms.Normalize([0.0692, 0.0692, 0.0692], [0.2051, 0.2051, 0.2051])\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = transformed_dataset.__getitem__(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (tensor([[[4.4427, 4.4809, 4.4236,  ..., 4.4809, 4.4809, 4.4618],\n",
       "           [4.4618, 4.4809, 4.4618,  ..., 4.4809, 4.4618, 4.4618],\n",
       "           [4.5000, 4.5000, 4.5000,  ..., 4.4618, 4.4618, 4.4809],\n",
       "           ...,\n",
       "           [4.4618, 4.5000, 4.5000,  ..., 4.4809, 4.4809, 4.4809],\n",
       "           [4.4618, 4.4809, 4.4809,  ..., 4.4618, 4.4618, 4.4809],\n",
       "           [4.4618, 4.4618, 4.4809,  ..., 4.4618, 4.4618, 4.4809]],\n",
       "  \n",
       "          [[4.4427, 4.4809, 4.4236,  ..., 4.4809, 4.4809, 4.4618],\n",
       "           [4.4618, 4.4809, 4.4618,  ..., 4.4809, 4.4618, 4.4618],\n",
       "           [4.5000, 4.5000, 4.5000,  ..., 4.4618, 4.4618, 4.4809],\n",
       "           ...,\n",
       "           [4.4618, 4.5000, 4.5000,  ..., 4.4809, 4.4809, 4.4809],\n",
       "           [4.4618, 4.4809, 4.4809,  ..., 4.4618, 4.4618, 4.4809],\n",
       "           [4.4618, 4.4618, 4.4809,  ..., 4.4618, 4.4618, 4.4809]],\n",
       "  \n",
       "          [[4.4427, 4.4809, 4.4236,  ..., 4.4809, 4.4809, 4.4618],\n",
       "           [4.4618, 4.4809, 4.4618,  ..., 4.4809, 4.4618, 4.4618],\n",
       "           [4.5000, 4.5000, 4.5000,  ..., 4.4618, 4.4618, 4.4809],\n",
       "           ...,\n",
       "           [4.4618, 4.5000, 4.5000,  ..., 4.4809, 4.4809, 4.4809],\n",
       "           [4.4618, 4.4809, 4.4809,  ..., 4.4618, 4.4618, 4.4809],\n",
       "           [4.4618, 4.4618, 4.4809,  ..., 4.4618, 4.4618, 4.4809]]]), 87))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tt), tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f710148d978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to_pil = transforms.ToPILImage() \n",
    "imshow(tt[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(transformed_dataset))\n",
    "val_size = len(transformed_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160672, 40168)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {}\n",
    "model_data['train'] = train_dataset\n",
    "model_data['val'] = val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataloader ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a Python process, the Global Interpreter Lock (GIL) prevents true fully parallelizing Python code across threads. To avoid blocking computation code with data loading, PyTorch provides an easy switch to perform multi-process data loading by simply setting the argument num_workers to a positive integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: DataLoader(model_data[x], \n",
    "                             batch_size=16,\n",
    "                             #shuffle=True, \n",
    "                             num_workers=4)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160672, 40168, 10042, 2511)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'].dataset), len(dataloaders['val'].dataset), len(dataloaders['train']), len(dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160672, 40168)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_names = dataloaders['train'].dataset.\n",
    "dataset_sizes['train'], dataset_sizes['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160672, 40168)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'].dataset), len(dataloaders['val'].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            end_time = time.time()\n",
    "            hours, rem = divmod(end_time-start_time, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch libraries and modules\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 168.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 168)\n",
    "\n",
    "# Ensuring the model is using GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# As we have two classes (0 or 1) we will use cross-entropy as criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD RESULTS: With approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.7334 Acc: 0.6115\n",
      "val Loss: 0.0802 Acc: 0.1790\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.2739 Acc: 0.7241\n",
      "val Loss: 0.0601 Acc: 0.1839\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.1872 Acc: 0.7467\n",
      "val Loss: 0.0570 Acc: 0.1850\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.1367 Acc: 0.7599\n",
      "val Loss: 0.0545 Acc: 0.1868\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.1027 Acc: 0.7698\n",
      "val Loss: 0.0544 Acc: 0.1869\n",
      "\n",
      "Training complete in 149m 36s\n",
      "Best val Acc: 0.186860\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6\n",
      "----------\n",
      "train Loss: 3.6868 Acc: 3.0489\n",
      "00:23:56.39\n",
      "val Loss: 1.6905 Acc: 3.5616\n",
      "00:05:57.25\n",
      "\n",
      "Epoch 1/6\n",
      "----------\n",
      "train Loss: 1.3652 Acc: 3.6202\n",
      "00:23:51.46\n",
      "val Loss: 1.1444 Acc: 3.7015\n",
      "00:05:55.55\n",
      "\n",
      "Epoch 2/6\n",
      "----------\n",
      "train Loss: 0.9378 Acc: 3.7312\n",
      "00:23:59.85\n",
      "val Loss: 1.0687 Acc: 3.7313\n",
      "00:05:57.39\n",
      "\n",
      "Epoch 3/6\n",
      "----------\n",
      "train Loss: 0.6845 Acc: 3.7998\n",
      "00:23:56.03\n",
      "val Loss: 1.0981 Acc: 3.7296\n",
      "00:05:56.34\n",
      "\n",
      "Epoch 4/6\n",
      "----------\n",
      "train Loss: 0.5099 Acc: 3.8495\n",
      "00:23:54.58\n",
      "val Loss: 1.0338 Acc: 3.7474\n",
      "00:05:56.51\n",
      "\n",
      "Epoch 5/6\n",
      "----------\n",
      "train Loss: 0.3718 Acc: 3.8876\n",
      "00:23:58.96\n",
      "val Loss: 1.1535 Acc: 3.7410\n",
      "00:05:59.80\n",
      "\n",
      "Epoch 6/6\n",
      "----------\n",
      "train Loss: 0.2848 Acc: 3.9145\n",
      "00:24:02.56\n",
      "val Loss: 1.1043 Acc: 3.7518\n",
      "00:05:56.65\n",
      "\n",
      "Training complete in 209m 19s\n",
      "Best val Acc: 3.751842\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 3.6696 Acc: 3.0595\n",
      "00:11:50.67\n",
      "val Loss: 1.5518 Acc: 3.5982\n",
      "00:02:04.41\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 1.3612 Acc: 3.6203\n",
      "00:11:50.42\n",
      "val Loss: 1.2887 Acc: 3.6550\n",
      "00:02:04.19\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.9254 Acc: 3.7371\n",
      "00:11:57.87\n",
      "val Loss: 1.0451 Acc: 3.7348\n",
      "00:02:06.26\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 3.8003\n",
      "00:11:53.31\n",
      "val Loss: 0.9907 Acc: 3.7541\n",
      "00:02:04.95\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.5029 Acc: 3.8491\n",
      "00:11:50.70\n",
      "val Loss: 1.1097 Acc: 3.7446\n",
      "00:02:05.50\n",
      "\n",
      "Training complete in 69m 48s\n",
      "Best val Acc: 3.754133\n"
     ]
    }
   ],
   "source": [
    "# With approach 2\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 168.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 168)\n",
    "\n",
    "# Ensuring the model is using GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# As we have two classes (0 or 1) we will use cross-entropy as criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 13.5778 Acc: 0.9490\n",
      "00:25:07.63\n",
      "val Loss: 3.3546 Acc: 3.0642\n",
      "00:02:24.22\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 2.3022 Acc: 3.3546\n",
      "00:25:11.42\n",
      "val Loss: 1.4499 Acc: 3.5963\n",
      "00:02:25.13\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 1.3052 Acc: 3.6267\n",
      "00:25:09.75\n",
      "val Loss: 1.1231 Acc: 3.6836\n",
      "00:02:23.83\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.9610 Acc: 3.7196\n",
      "00:25:12.55\n",
      "val Loss: 1.0719 Acc: 3.6993\n",
      "00:02:23.55\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.7478 Acc: 3.7787\n",
      "00:25:13.44\n",
      "val Loss: 0.9800 Acc: 3.7264\n",
      "00:02:23.82\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6021 Acc: 3.8174\n",
      "00:25:07.31\n",
      "val Loss: 1.0181 Acc: 3.7206\n",
      "00:02:21.26\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.4906 Acc: 3.8480\n",
      "00:25:11.23\n",
      "val Loss: 0.9787 Acc: 3.7318\n",
      "00:02:20.76\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.3975 Acc: 3.8761\n",
      "00:25:09.99\n",
      "val Loss: 0.9574 Acc: 3.7394\n",
      "00:02:26.19\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.1617 Acc: 3.9525\n",
      "00:25:11.29\n",
      "val Loss: 0.8218 Acc: 3.7905\n",
      "00:02:24.14\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1122 Acc: 3.9689\n",
      "00:25:08.65\n",
      "val Loss: 0.8541 Acc: 3.7929\n",
      "00:02:22.48\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.0899 Acc: 3.9762\n",
      "00:25:12.09\n",
      "val Loss: 0.8859 Acc: 3.7928\n",
      "00:02:22.25\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0738 Acc: 3.9808\n",
      "00:25:12.56\n",
      "val Loss: 0.9011 Acc: 3.7919\n",
      "00:02:22.83\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0634 Acc: 3.9842\n",
      "00:25:10.11\n",
      "val Loss: 0.9279 Acc: 3.7932\n",
      "00:02:21.08\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0529 Acc: 3.9871\n",
      "00:25:10.98\n",
      "val Loss: 0.9688 Acc: 3.7904\n",
      "00:02:23.72\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0437 Acc: 3.9897\n",
      "00:25:11.79\n",
      "val Loss: 0.9878 Acc: 3.7914\n",
      "00:02:21.10\n",
      "\n",
      "Training complete in 413m 27s\n",
      "Best val Acc: 3.793169\n"
     ]
    }
   ],
   "source": [
    "# With approach 2\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 168.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 168)\n",
    "\n",
    "# Ensuring the model is using GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# As we have two classes (0 or 1) we will use cross-entropy as criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach 2, new way of val data generation, changed dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 1.0742 Acc: 0.7486\n",
      "00:16:23.54\n",
      "val Loss: 0.3536 Acc: 0.9010\n",
      "00:01:59.31\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.2793 Acc: 0.9250\n",
      "00:16:02.01\n",
      "val Loss: 0.2732 Acc: 0.9248\n",
      "00:01:59.82\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9591\n",
      "00:16:06.05\n",
      "val Loss: 0.2656 Acc: 0.9301\n",
      "00:01:59.03\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.0924 Acc: 0.9760\n",
      "00:16:00.26\n",
      "val Loss: 0.2601 Acc: 0.9334\n",
      "00:01:59.10\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.0590 Acc: 0.9850\n",
      "00:15:59.61\n",
      "val Loss: 0.2715 Acc: 0.9351\n",
      "00:01:59.23\n",
      "\n",
      "Training complete in 90m 28s\n",
      "Best val Acc: 0.935073\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 168.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 168)\n",
    "\n",
    "# Ensuring the model is using GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# As we have two classes (0 or 1) we will use cross-entropy as criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.8474 Acc: 0.7985\n",
      "00:39:34.09\n",
      "val Loss: 0.3058 Acc: 0.9172\n",
      "00:03:15.10\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.2272 Acc: 0.9395\n",
      "00:39:37.86\n",
      "val Loss: 0.2478 Acc: 0.9340\n",
      "00:03:15.32\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9661\n",
      "00:39:37.92\n",
      "val Loss: 0.2402 Acc: 0.9393\n",
      "00:03:15.53\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0823 Acc: 0.9777\n",
      "00:39:37.54\n",
      "val Loss: 0.2385 Acc: 0.9429\n",
      "00:03:15.66\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0573 Acc: 0.9839\n",
      "00:39:39.07\n",
      "val Loss: 0.2635 Acc: 0.9382\n",
      "00:03:15.73\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0413 Acc: 0.9884\n",
      "00:39:39.99\n",
      "val Loss: 0.2680 Acc: 0.9425\n",
      "00:03:15.89\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9911\n",
      "00:39:39.88\n",
      "val Loss: 0.2802 Acc: 0.9413\n",
      "00:03:16.01\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0293 Acc: 0.9919\n",
      "00:39:41.41\n",
      "val Loss: 0.2784 Acc: 0.9443\n",
      "00:03:15.10\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 0.9976\n",
      "00:39:29.44\n",
      "val Loss: 0.2423 Acc: 0.9542\n",
      "00:03:14.47\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 0.9998\n",
      "00:39:24.24\n",
      "val Loss: 0.2465 Acc: 0.9544\n",
      "00:03:13.56\n",
      "\n",
      "Training complete in 428m 34s\n",
      "Best val Acc: 0.954392\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'grapheme-root-base.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our model is overfitting with 99.99% accuracy on training dataset and 95% accuracy on validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add dropout of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 168.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 168)\n",
    "model_ft.fc = nn.Dropout(0.5)\n",
    "\n",
    "# Ensuring the model is using GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# As we have two classes (0 or 1) we will use cross-entropy as criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 4.9064 Acc: 0.3743\n",
      "00:39:28.66\n",
      "val Loss: 1.7101 Acc: 0.8835\n",
      "00:03:14.04\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 4.2530 Acc: 0.4639\n",
      "00:39:33.48\n",
      "val Loss: 1.2661 Acc: 0.9164\n",
      "00:03:14.54\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 4.1477 Acc: 0.4746\n",
      "00:39:32.52\n",
      "val Loss: 1.0021 Acc: 0.9259\n",
      "00:03:14.45\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-80b427a3cf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=15)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-676960e6f38c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dropout of 0.5 seems too much. Let'ds yty with 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 168.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 168)\n",
    "model_ft.fc = nn.Dropout(0.2)\n",
    "\n",
    "# Ensuring the model is using GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# As we have two classes (0 or 1) we will use cross-entropy as criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 2.9967 Acc: 0.5881\n",
      "00:39:31.37\n",
      "val Loss: 0.4949 Acc: 0.8971\n",
      "00:03:14.78\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 2.0227 Acc: 0.7387\n",
      "00:39:46.27\n",
      "val Loss: 0.3836 Acc: 0.9248\n",
      "00:03:15.14\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 1.8984 Acc: 0.7587\n",
      "00:39:33.78\n",
      "val Loss: 0.3536 Acc: 0.9335\n",
      "00:03:14.87\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 1.8189 Acc: 0.7699\n",
      "00:39:31.68\n",
      "val Loss: 0.3596 Acc: 0.9365\n",
      "00:03:14.68\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 1.7831 Acc: 0.7737\n",
      "00:39:29.96\n",
      "val Loss: 0.3625 Acc: 0.9392\n",
      "00:03:14.17\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 1.7363 Acc: 0.7800\n",
      "00:39:30.01\n",
      "val Loss: 0.3940 Acc: 0.9383\n",
      "00:03:14.67\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 1.7000 Acc: 0.7845\n",
      "00:39:30.12\n",
      "val Loss: 0.3784 Acc: 0.9434\n",
      "00:03:14.59\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 1.6830 Acc: 0.7861\n",
      "00:39:29.06\n",
      "val Loss: 0.3866 Acc: 0.9443\n",
      "00:03:14.60\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 1.6330 Acc: 0.7931\n",
      "00:39:29.21\n",
      "val Loss: 0.3287 Acc: 0.9537\n",
      "00:03:14.40\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 1.6103 Acc: 0.7964\n",
      "00:39:26.96\n",
      "val Loss: 0.3369 Acc: 0.9544\n",
      "00:03:14.38\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 1.6069 Acc: 0.7967\n",
      "00:39:26.70\n",
      "val Loss: 0.3426 Acc: 0.9549\n",
      "00:03:14.24\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 1.5984 Acc: 0.7977\n",
      "00:39:24.87\n",
      "val Loss: 0.3480 Acc: 0.9553\n",
      "00:03:14.24\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 1.5833 Acc: 0.7995\n",
      "00:39:25.42\n",
      "val Loss: 0.3566 Acc: 0.9553\n",
      "00:03:14.05\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 1.5889 Acc: 0.7987\n",
      "00:39:25.82\n",
      "val Loss: 0.3602 Acc: 0.9553\n",
      "00:03:14.54\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 1.5980 Acc: 0.7973\n",
      "00:39:37.96\n",
      "val Loss: 0.3669 Acc: 0.9555\n",
      "00:03:14.16\n",
      "\n",
      "Training complete in 641m 17s\n",
      "Best val Acc: 0.955487\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
