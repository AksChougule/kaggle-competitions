{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchsummary\n",
    "# !pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torchvision import models\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (fc): None\n",
       "  (last_linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ by looking at the last layer above here, we change it to 3 separate layers based on number of classes in each classfication task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the last layers of ResNet34 look like:\n",
    "    \n",
    "    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
    "    (fc): None\n",
    "    (last_linear): Linear(in_features=512, out_features=1000, bias=True)\n",
    "        \n",
    "So we will add 512\\*num_of_possible_classes for each head. That is 512\\*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet34, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
    "        \n",
    "        self.l0 = nn.Linear(512, 2)  # nucleoplasmn\n",
    "        self.l1 = nn.Linear(512, 2)  # nuclear_membrane\n",
    "        self.l2 = nn.Linear(512, 2)  # nucleoli\n",
    "        self.l3 = nn.Linear(512, 2)  # nucleoli_fibrillar_center\n",
    "        self.l4 = nn.Linear(512, 2)  # nuclear_speckles\n",
    "        self.l5 = nn.Linear(512, 2)  # nuclear_bodies\n",
    "        self.l6 = nn.Linear(512, 2)  # endoplasmic_reticulum\n",
    "        self.l7 = nn.Linear(512, 2)  # golgi_apparatus\n",
    "        self.l8 = nn.Linear(512, 2)  # peroxisomes\n",
    "        self.l9 = nn.Linear(512, 2)  # endosomes\n",
    "        self.l10 = nn.Linear(512, 2)  # lysosomes\n",
    "        self.l11 = nn.Linear(512, 2)  # intermediate_filaments\n",
    "        self.l12 = nn.Linear(512, 2)  # actin_filaments\n",
    "        self.l13 = nn.Linear(512, 2)  # focal_adhesion_sites\n",
    "        self.l14 = nn.Linear(512, 2)  # microtubules\n",
    "        self.l15 = nn.Linear(512, 2)  # microtubule_ends\n",
    "        self.l16 = nn.Linear(512, 2)  # cytokinetic_bridge\n",
    "        self.l17 = nn.Linear(512, 2)  # mitotic_spindle\n",
    "        self.l18 = nn.Linear(512, 2)  # microtubule_organizing_center\n",
    "        self.l19 = nn.Linear(512, 2)  # centrosome\n",
    "        self.l20 = nn.Linear(512, 2)  # lipid_droplets\n",
    "        self.l21 = nn.Linear(512, 2)  # plasma_membrane\n",
    "        self.l22 = nn.Linear(512, 2)  # cell_junctions\n",
    "        self.l23 = nn.Linear(512, 2)  # mitochondria\n",
    "        self.l24 = nn.Linear(512, 2)  # aggresome\n",
    "        self.l25 = nn.Linear(512, 2)  # cytosol\n",
    "        self.l26 = nn.Linear(512, 2)  # cytoplasmic_bodies\n",
    "        self.l27 = nn.Linear(512, 2)  # rods_rings\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        # Adaptive pooling supports all image sizes\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        l0  = self.l0(x)\n",
    "        l1  = self.l1(x)\n",
    "        l2  = self.l2(x)\n",
    "        l3  = self.l3(x)\n",
    "        l4  = self.l4(x)\n",
    "        l5  = self.l5(x)\n",
    "        l6  = self.l6(x)\n",
    "        l7  = self.l7(x)\n",
    "        l8  = self.l8(x)\n",
    "        l9  = self.l9(x)\n",
    "        l10  = self.l10(x)\n",
    "        l11  = self.l11(x)\n",
    "        l12  = self.l12(x)\n",
    "        l13  = self.l13(x)\n",
    "        l14  = self.l14(x)\n",
    "        l15  = self.l15(x)\n",
    "        l16  = self.l16(x)\n",
    "        l17  = self.l17(x)\n",
    "        l18  = self.l18(x)\n",
    "        l19  = self.l19(x)\n",
    "        l20  = self.l20(x)\n",
    "        l21  = self.l21(x)\n",
    "        l22  = self.l22(x)\n",
    "        l23  = self.l23(x)\n",
    "        l24  = self.l24(x)\n",
    "        l25  = self.l25(x)\n",
    "        l26  = self.l26(x)\n",
    "        l27  = self.l27(x)\n",
    "\n",
    "        return l0, l1, l2, l3, l4, l5, l6, l7, l8, l9, l10, l11, l12, l13, l14, l15, l16, l17, l18, l19, l20, l21, l22, l23, l24, l25, l26, l27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet34(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "    (fc): None\n",
       "    (last_linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (l0): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l1): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l3): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l4): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l5): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l6): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l7): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l9): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l10): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l11): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l12): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l13): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l14): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l15): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l16): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l17): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l18): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l19): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l20): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l21): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l22): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l23): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l24): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l25): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l26): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (l27): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet34(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ This looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now let's create next customer model using ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (fc): None\n",
       "  (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the last layer of the original ResNet50 looks like:\n",
    "    \n",
    "    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
    "    (fc): None\n",
    "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "\n",
    "So we will add 2048\\*num_of_possible_classes for each head. That is 2048\\*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet50, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=\"imagenet\")\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet50\"](pretrained=None)\n",
    "\n",
    "        self.l0 = nn.Linear(2048, 2)  # nucleoplasmn\n",
    "        self.l1 = nn.Linear(2048, 2)  # nuclear_membrane\n",
    "        self.l2 = nn.Linear(2048, 2)  # nucleoli\n",
    "        self.l3 = nn.Linear(2048, 2)  # nucleoli_fibrillar_center\n",
    "        self.l4 = nn.Linear(2048, 2)  # nuclear_speckles\n",
    "        self.l5 = nn.Linear(2048, 2)  # nuclear_bodies\n",
    "        self.l6 = nn.Linear(2048, 2)  # endoplasmic_reticulum\n",
    "        self.l7 = nn.Linear(2048, 2)  # golgi_apparatus\n",
    "        self.l8 = nn.Linear(2048, 2)  # peroxisomes\n",
    "        self.l9 = nn.Linear(2048, 2)  # endosomes\n",
    "        self.l10 = nn.Linear(2048, 2)  # lysosomes\n",
    "        self.l11 = nn.Linear(2048, 2)  # intermediate_filaments\n",
    "        self.l12 = nn.Linear(2048, 2)  # actin_filaments\n",
    "        self.l13 = nn.Linear(2048, 2)  # focal_adhesion_sites\n",
    "        self.l14 = nn.Linear(2048, 2)  # microtubules\n",
    "        self.l15 = nn.Linear(2048, 2)  # microtubule_ends\n",
    "        self.l16 = nn.Linear(2048, 2)  # cytokinetic_bridge\n",
    "        self.l17 = nn.Linear(2048, 2)  # mitotic_spindle\n",
    "        self.l18 = nn.Linear(2048, 2)  # microtubule_organizing_center\n",
    "        self.l19 = nn.Linear(2048, 2)  # centrosome\n",
    "        self.l20 = nn.Linear(2048, 2)  # lipid_droplets\n",
    "        self.l21 = nn.Linear(2048, 2)  # plasma_membrane\n",
    "        self.l22 = nn.Linear(2048, 2)  # cell_junctions\n",
    "        self.l23 = nn.Linear(2048, 2)  # mitochondria\n",
    "        self.l24 = nn.Linear(2048, 2)  # aggresome\n",
    "        self.l25 = nn.Linear(2048, 2)  # cytosol\n",
    "        self.l26 = nn.Linear(2048, 2)  # cytoplasmic_bodies\n",
    "        self.l27 = nn.Linear(2048, 2)  # rods_rings\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        print(x.shape) # The dim is: bs * 2048 * 16 * 16 for images of size 3*512*512\n",
    "        # Adaptive pooling supports all image sizes\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        print(x.shape) # The dim is: bs * 2048\n",
    "        l0  = self.l0(x)\n",
    "        l1  = self.l1(x)\n",
    "        l2  = self.l2(x)\n",
    "        l3  = self.l3(x)\n",
    "        l4  = self.l4(x)\n",
    "        l5  = self.l5(x)\n",
    "        l6  = self.l6(x)\n",
    "        l7  = self.l7(x)\n",
    "        l8  = self.l8(x)\n",
    "        l9  = self.l9(x)\n",
    "        l10  = self.l10(x)\n",
    "        l11  = self.l11(x)\n",
    "        l12  = self.l12(x)\n",
    "        l13  = self.l13(x)\n",
    "        l14  = self.l14(x)\n",
    "        l15  = self.l15(x)\n",
    "        l16  = self.l16(x)\n",
    "        l17  = self.l17(x)\n",
    "        l18  = self.l18(x)\n",
    "        l19  = self.l19(x)\n",
    "        l20  = self.l20(x)\n",
    "        l21  = self.l21(x)\n",
    "        l22  = self.l22(x)\n",
    "        l23  = self.l23(x)\n",
    "        l24  = self.l24(x)\n",
    "        l25  = self.l25(x)\n",
    "        l26  = self.l26(x)\n",
    "        l27  = self.l27(x)\n",
    "\n",
    "        return l0, l1, l2, l3, l4, l5, l6, l7, l8, l9, l10, l11, l12, l13, l14, l15, l16, l17, l18, l19, l20, l21, l22, l23, l24, l25, l26, l27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "    (fc): None\n",
       "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (l0): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l1): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l2): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l3): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l4): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l5): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l6): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l7): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l8): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l9): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l10): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l11): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l12): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l13): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l14): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l15): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l16): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l17): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l18): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l19): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l20): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l21): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l22): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l23): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l24): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l25): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l26): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  (l27): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ This looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look into model parametrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ilshift__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rmul__', '__rpow__', '__rshift__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_dimI', '_dimV', '_grad', '_grad_fn', '_indices', '_make_subclass', '_nnz', '_values', '_version', 'abs', 'abs_', 'acos', 'acos_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'all', 'allclose', 'any', 'apply_', 'argmax', 'argmin', 'argsort', 'as_strided', 'as_strided_', 'asin', 'asin_', 'atan', 'atan2', 'atan2_', 'atan_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bincount', 'bmm', 'btrifact', 'btrifact_with_info', 'btrisolve', 'byte', 'cauchy_', 'ceil', 'ceil_', 'char', 'cholesky', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clone', 'coalesce', 'contiguous', 'copy_', 'cos', 'cos_', 'cosh', 'cosh_', 'cpu', 'cross', 'cuda', 'cumprod', 'cumsum', 'data', 'data_ptr', 'dense_dim', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'dot', 'double', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fft', 'fill_', 'flatten', 'flip', 'float', 'floor', 'floor_', 'fmod', 'fmod_', 'frac', 'frac_', 'gather', 'ge', 'ge_', 'gels', 'geometric_', 'geqrf', 'ger', 'gesv', 'get_device', 'grad', 'grad_fn', 'gt', 'gt_', 'half', 'hardshrink', 'histc', 'ifft', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'int', 'inverse', 'irfft', 'is_coalesced', 'is_complex', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_leaf', 'is_nonzero', 'is_pinned', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'isclose', 'item', 'kthvalue', 'layout', 'le', 'le_', 'lerp', 'lerp_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logdet', 'logsumexp', 'long', 'lt', 'lt_', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_power', 'max', 'mean', 'median', 'min', 'mm', 'mode', 'mul', 'mul_', 'multinomial', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'narrow', 'narrow_copy', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'nelement', 'new', 'new_empty', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nonzero', 'norm', 'normal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'potrf', 'potri', 'potrs', 'pow', 'pow_', 'prelu', 'prod', 'pstrf', 'put_', 'qr', 'random_', 'reciprocal', 'reciprocal_', 'record_stream', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'renorm', 'renorm_', 'repeat', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'retain_grad', 'rfft', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'select', 'set_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'sin', 'sin_', 'sinh', 'sinh_', 'size', 'slogdet', 'smm', 'softmax', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'sum', 'svd', 'symeig', 't', 't_', 'take', 'tan', 'tan_', 'tanh', 'tanh_', 'to', 'to_dense', 'to_sparse', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'tril', 'tril_', 'triu', 'triu_', 'trtrs', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unfold', 'uniform_', 'unique', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'view', 'view_as', 'where', 'zero_']\n"
     ]
    }
   ],
   "source": [
    "for params in model.parameters():\n",
    "    print(dir(params))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ We can see `requires_grad` here which would help us freeze or unfreeze the training layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(model: nn.Module):\n",
    "    \"\"\"Freeze all model parameters.\"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def unfreeze(model: nn.Module):\n",
    "    \"\"\"Unfreeze all model parameters.\"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now let's look into how can we apply differntial learning rate__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass options as keyword arguments. They will be used as defaults, in the groups that didnt override them. This is useful when you only want to vary a single option, while keeping all others consistent between parameter groups. - [PyTorch Optim](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight\n",
      "model.bn1.weight\n",
      "model.bn1.bias\n",
      "model.layer1.0.conv1.weight\n",
      "model.layer1.0.bn1.weight\n",
      "model.layer1.0.bn1.bias\n",
      "model.layer1.0.conv2.weight\n",
      "model.layer1.0.bn2.weight\n",
      "model.layer1.0.bn2.bias\n",
      "model.layer1.0.conv3.weight\n",
      "model.layer1.0.bn3.weight\n",
      "model.layer1.0.bn3.bias\n",
      "model.layer1.0.downsample.0.weight\n",
      "model.layer1.0.downsample.1.weight\n",
      "model.layer1.0.downsample.1.bias\n",
      "model.layer1.1.conv1.weight\n",
      "model.layer1.1.bn1.weight\n",
      "model.layer1.1.bn1.bias\n",
      "model.layer1.1.conv2.weight\n",
      "model.layer1.1.bn2.weight\n",
      "model.layer1.1.bn2.bias\n",
      "model.layer1.1.conv3.weight\n",
      "model.layer1.1.bn3.weight\n",
      "model.layer1.1.bn3.bias\n",
      "model.layer1.2.conv1.weight\n",
      "model.layer1.2.bn1.weight\n",
      "model.layer1.2.bn1.bias\n",
      "model.layer1.2.conv2.weight\n",
      "model.layer1.2.bn2.weight\n",
      "model.layer1.2.bn2.bias\n",
      "model.layer1.2.conv3.weight\n",
      "model.layer1.2.bn3.weight\n",
      "model.layer1.2.bn3.bias\n",
      "model.layer2.0.conv1.weight\n",
      "model.layer2.0.bn1.weight\n",
      "model.layer2.0.bn1.bias\n",
      "model.layer2.0.conv2.weight\n",
      "model.layer2.0.bn2.weight\n",
      "model.layer2.0.bn2.bias\n",
      "model.layer2.0.conv3.weight\n",
      "model.layer2.0.bn3.weight\n",
      "model.layer2.0.bn3.bias\n",
      "model.layer2.0.downsample.0.weight\n",
      "model.layer2.0.downsample.1.weight\n",
      "model.layer2.0.downsample.1.bias\n",
      "model.layer2.1.conv1.weight\n",
      "model.layer2.1.bn1.weight\n",
      "model.layer2.1.bn1.bias\n",
      "model.layer2.1.conv2.weight\n",
      "model.layer2.1.bn2.weight\n",
      "model.layer2.1.bn2.bias\n",
      "model.layer2.1.conv3.weight\n",
      "model.layer2.1.bn3.weight\n",
      "model.layer2.1.bn3.bias\n",
      "model.layer2.2.conv1.weight\n",
      "model.layer2.2.bn1.weight\n",
      "model.layer2.2.bn1.bias\n",
      "model.layer2.2.conv2.weight\n",
      "model.layer2.2.bn2.weight\n",
      "model.layer2.2.bn2.bias\n",
      "model.layer2.2.conv3.weight\n",
      "model.layer2.2.bn3.weight\n",
      "model.layer2.2.bn3.bias\n",
      "model.layer2.3.conv1.weight\n",
      "model.layer2.3.bn1.weight\n",
      "model.layer2.3.bn1.bias\n",
      "model.layer2.3.conv2.weight\n",
      "model.layer2.3.bn2.weight\n",
      "model.layer2.3.bn2.bias\n",
      "model.layer2.3.conv3.weight\n",
      "model.layer2.3.bn3.weight\n",
      "model.layer2.3.bn3.bias\n",
      "model.layer3.0.conv1.weight\n",
      "model.layer3.0.bn1.weight\n",
      "model.layer3.0.bn1.bias\n",
      "model.layer3.0.conv2.weight\n",
      "model.layer3.0.bn2.weight\n",
      "model.layer3.0.bn2.bias\n",
      "model.layer3.0.conv3.weight\n",
      "model.layer3.0.bn3.weight\n",
      "model.layer3.0.bn3.bias\n",
      "model.layer3.0.downsample.0.weight\n",
      "model.layer3.0.downsample.1.weight\n",
      "model.layer3.0.downsample.1.bias\n",
      "model.layer3.1.conv1.weight\n",
      "model.layer3.1.bn1.weight\n",
      "model.layer3.1.bn1.bias\n",
      "model.layer3.1.conv2.weight\n",
      "model.layer3.1.bn2.weight\n",
      "model.layer3.1.bn2.bias\n",
      "model.layer3.1.conv3.weight\n",
      "model.layer3.1.bn3.weight\n",
      "model.layer3.1.bn3.bias\n",
      "model.layer3.2.conv1.weight\n",
      "model.layer3.2.bn1.weight\n",
      "model.layer3.2.bn1.bias\n",
      "model.layer3.2.conv2.weight\n",
      "model.layer3.2.bn2.weight\n",
      "model.layer3.2.bn2.bias\n",
      "model.layer3.2.conv3.weight\n",
      "model.layer3.2.bn3.weight\n",
      "model.layer3.2.bn3.bias\n",
      "model.layer3.3.conv1.weight\n",
      "model.layer3.3.bn1.weight\n",
      "model.layer3.3.bn1.bias\n",
      "model.layer3.3.conv2.weight\n",
      "model.layer3.3.bn2.weight\n",
      "model.layer3.3.bn2.bias\n",
      "model.layer3.3.conv3.weight\n",
      "model.layer3.3.bn3.weight\n",
      "model.layer3.3.bn3.bias\n",
      "model.layer3.4.conv1.weight\n",
      "model.layer3.4.bn1.weight\n",
      "model.layer3.4.bn1.bias\n",
      "model.layer3.4.conv2.weight\n",
      "model.layer3.4.bn2.weight\n",
      "model.layer3.4.bn2.bias\n",
      "model.layer3.4.conv3.weight\n",
      "model.layer3.4.bn3.weight\n",
      "model.layer3.4.bn3.bias\n",
      "model.layer3.5.conv1.weight\n",
      "model.layer3.5.bn1.weight\n",
      "model.layer3.5.bn1.bias\n",
      "model.layer3.5.conv2.weight\n",
      "model.layer3.5.bn2.weight\n",
      "model.layer3.5.bn2.bias\n",
      "model.layer3.5.conv3.weight\n",
      "model.layer3.5.bn3.weight\n",
      "model.layer3.5.bn3.bias\n",
      "model.layer4.0.conv1.weight\n",
      "model.layer4.0.bn1.weight\n",
      "model.layer4.0.bn1.bias\n",
      "model.layer4.0.conv2.weight\n",
      "model.layer4.0.bn2.weight\n",
      "model.layer4.0.bn2.bias\n",
      "model.layer4.0.conv3.weight\n",
      "model.layer4.0.bn3.weight\n",
      "model.layer4.0.bn3.bias\n",
      "model.layer4.0.downsample.0.weight\n",
      "model.layer4.0.downsample.1.weight\n",
      "model.layer4.0.downsample.1.bias\n",
      "model.layer4.1.conv1.weight\n",
      "model.layer4.1.bn1.weight\n",
      "model.layer4.1.bn1.bias\n",
      "model.layer4.1.conv2.weight\n",
      "model.layer4.1.bn2.weight\n",
      "model.layer4.1.bn2.bias\n",
      "model.layer4.1.conv3.weight\n",
      "model.layer4.1.bn3.weight\n",
      "model.layer4.1.bn3.bias\n",
      "model.layer4.2.conv1.weight\n",
      "model.layer4.2.bn1.weight\n",
      "model.layer4.2.bn1.bias\n",
      "model.layer4.2.conv2.weight\n",
      "model.layer4.2.bn2.weight\n",
      "model.layer4.2.bn2.bias\n",
      "model.layer4.2.conv3.weight\n",
      "model.layer4.2.bn3.weight\n",
      "model.layer4.2.bn3.bias\n",
      "model.last_linear.weight\n",
      "model.last_linear.bias\n",
      "l0.weight\n",
      "l0.bias\n",
      "l1.weight\n",
      "l1.bias\n",
      "l2.weight\n",
      "l2.bias\n",
      "l3.weight\n",
      "l3.bias\n",
      "l4.weight\n",
      "l4.bias\n",
      "l5.weight\n",
      "l5.bias\n",
      "l6.weight\n",
      "l6.bias\n",
      "l7.weight\n",
      "l7.bias\n",
      "l8.weight\n",
      "l8.bias\n",
      "l9.weight\n",
      "l9.bias\n",
      "l10.weight\n",
      "l10.bias\n",
      "l11.weight\n",
      "l11.bias\n",
      "l12.weight\n",
      "l12.bias\n",
      "l13.weight\n",
      "l13.bias\n",
      "l14.weight\n",
      "l14.bias\n",
      "l15.weight\n",
      "l15.bias\n",
      "l16.weight\n",
      "l16.bias\n",
      "l17.weight\n",
      "l17.bias\n",
      "l18.weight\n",
      "l18.bias\n",
      "l19.weight\n",
      "l19.bias\n",
      "l20.weight\n",
      "l20.bias\n",
      "l21.weight\n",
      "l21.bias\n",
      "l22.weight\n",
      "l22.bias\n",
      "l23.weight\n",
      "l23.bias\n",
      "l24.weight\n",
      "l24.bias\n",
      "l25.weight\n",
      "l25.bias\n",
      "l26.weight\n",
      "l26.bias\n",
      "l27.weight\n",
      "l27.bias\n"
     ]
    }
   ],
   "source": [
    "# Let's get the name of each trainable layer \n",
    "for name, param in model.named_parameters():\n",
    "    # if requires grad is True then that layer is available for training\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print name, param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ilshift__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rmul__', '__rpow__', '__rshift__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_dimI', '_dimV', '_grad', '_grad_fn', '_indices', '_make_subclass', '_nnz', '_values', '_version', 'abs', 'abs_', 'acos', 'acos_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'all', 'allclose', 'any', 'apply_', 'argmax', 'argmin', 'argsort', 'as_strided', 'as_strided_', 'asin', 'asin_', 'atan', 'atan2', 'atan2_', 'atan_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bincount', 'bmm', 'btrifact', 'btrifact_with_info', 'btrisolve', 'byte', 'cauchy_', 'ceil', 'ceil_', 'char', 'cholesky', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clone', 'coalesce', 'contiguous', 'copy_', 'cos', 'cos_', 'cosh', 'cosh_', 'cpu', 'cross', 'cuda', 'cumprod', 'cumsum', 'data', 'data_ptr', 'dense_dim', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'dot', 'double', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fft', 'fill_', 'flatten', 'flip', 'float', 'floor', 'floor_', 'fmod', 'fmod_', 'frac', 'frac_', 'gather', 'ge', 'ge_', 'gels', 'geometric_', 'geqrf', 'ger', 'gesv', 'get_device', 'grad', 'grad_fn', 'gt', 'gt_', 'half', 'hardshrink', 'histc', 'ifft', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'int', 'inverse', 'irfft', 'is_coalesced', 'is_complex', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_leaf', 'is_nonzero', 'is_pinned', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'isclose', 'item', 'kthvalue', 'layout', 'le', 'le_', 'lerp', 'lerp_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logdet', 'logsumexp', 'long', 'lt', 'lt_', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_power', 'max', 'mean', 'median', 'min', 'mm', 'mode', 'mul', 'mul_', 'multinomial', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'narrow', 'narrow_copy', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'nelement', 'new', 'new_empty', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nonzero', 'norm', 'normal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'potrf', 'potri', 'potrs', 'pow', 'pow_', 'prelu', 'prod', 'pstrf', 'put_', 'qr', 'random_', 'reciprocal', 'reciprocal_', 'record_stream', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'renorm', 'renorm_', 'repeat', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'retain_grad', 'rfft', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'select', 'set_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'sin', 'sin_', 'sinh', 'sinh_', 'size', 'slogdet', 'smm', 'softmax', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'sum', 'svd', 'symeig', 't', 't_', 'take', 'tan', 'tan_', 'tanh', 'tanh_', 'to', 'to_dense', 'to_sparse', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'tril', 'tril_', 'triu', 'triu_', 'trtrs', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unfold', 'uniform_', 'unique', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'view', 'view_as', 'where', 'zero_']\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(dir(param))\n",
    "        #print(param.name)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This did not work\n",
    "# summary(model,(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's play with the default model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.conv3.weight\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.0.downsample.0.weight\n",
      "layer1.0.downsample.1.weight\n",
      "layer1.0.downsample.1.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.conv3.weight\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.conv3.weight\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.conv3.weight\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.conv3.weight\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.conv3.weight\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.conv3.weight\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.conv3.weight\n",
      "layer3.0.bn3.weight\n",
      "layer3.0.bn3.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.conv3.weight\n",
      "layer3.1.bn3.weight\n",
      "layer3.1.bn3.bias\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.conv3.weight\n",
      "layer3.2.bn3.weight\n",
      "layer3.2.bn3.bias\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.conv3.weight\n",
      "layer3.3.bn3.weight\n",
      "layer3.3.bn3.bias\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.conv3.weight\n",
      "layer3.4.bn3.weight\n",
      "layer3.4.bn3.bias\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.conv3.weight\n",
      "layer3.5.bn3.weight\n",
      "layer3.5.bn3.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.conv3.weight\n",
      "layer4.0.bn3.weight\n",
      "layer4.0.bn3.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.conv3.weight\n",
      "layer4.1.bn3.weight\n",
      "layer4.1.bn3.bias\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.conv3.weight\n",
      "layer4.2.bn3.weight\n",
      "layer4.2.bn3.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        #print(dir(param))\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As specified in torch.optim documentation we divide model layers into multiple buckets (in following case 3) and train each bucket with a different learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_groups = [\n",
    "    [model.conv1, model.bn1, model.layer1, model.layer2],\n",
    "    [model.layer3, model.layer4],\n",
    "    [model.fc.weight, model.fc.bias]\n",
    "]\n",
    "\n",
    "lrs = np.array([lr / 10, lr / 3, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ This is how we can create 3 separate buckets for 3 separate learning rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now let's let's try the same for our custom model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight\n",
      "model.bn1.weight\n",
      "model.bn1.bias\n",
      "model.layer1.0.conv1.weight\n",
      "model.layer1.0.bn1.weight\n",
      "model.layer1.0.bn1.bias\n",
      "model.layer1.0.conv2.weight\n",
      "model.layer1.0.bn2.weight\n",
      "model.layer1.0.bn2.bias\n",
      "model.layer1.0.conv3.weight\n",
      "model.layer1.0.bn3.weight\n",
      "model.layer1.0.bn3.bias\n",
      "model.layer1.0.downsample.0.weight\n",
      "model.layer1.0.downsample.1.weight\n",
      "model.layer1.0.downsample.1.bias\n",
      "model.layer1.1.conv1.weight\n",
      "model.layer1.1.bn1.weight\n",
      "model.layer1.1.bn1.bias\n",
      "model.layer1.1.conv2.weight\n",
      "model.layer1.1.bn2.weight\n",
      "model.layer1.1.bn2.bias\n",
      "model.layer1.1.conv3.weight\n",
      "model.layer1.1.bn3.weight\n",
      "model.layer1.1.bn3.bias\n",
      "model.layer1.2.conv1.weight\n",
      "model.layer1.2.bn1.weight\n",
      "model.layer1.2.bn1.bias\n",
      "model.layer1.2.conv2.weight\n",
      "model.layer1.2.bn2.weight\n",
      "model.layer1.2.bn2.bias\n",
      "model.layer1.2.conv3.weight\n",
      "model.layer1.2.bn3.weight\n",
      "model.layer1.2.bn3.bias\n",
      "model.layer2.0.conv1.weight\n",
      "model.layer2.0.bn1.weight\n",
      "model.layer2.0.bn1.bias\n",
      "model.layer2.0.conv2.weight\n",
      "model.layer2.0.bn2.weight\n",
      "model.layer2.0.bn2.bias\n",
      "model.layer2.0.conv3.weight\n",
      "model.layer2.0.bn3.weight\n",
      "model.layer2.0.bn3.bias\n",
      "model.layer2.0.downsample.0.weight\n",
      "model.layer2.0.downsample.1.weight\n",
      "model.layer2.0.downsample.1.bias\n",
      "model.layer2.1.conv1.weight\n",
      "model.layer2.1.bn1.weight\n",
      "model.layer2.1.bn1.bias\n",
      "model.layer2.1.conv2.weight\n",
      "model.layer2.1.bn2.weight\n",
      "model.layer2.1.bn2.bias\n",
      "model.layer2.1.conv3.weight\n",
      "model.layer2.1.bn3.weight\n",
      "model.layer2.1.bn3.bias\n",
      "model.layer2.2.conv1.weight\n",
      "model.layer2.2.bn1.weight\n",
      "model.layer2.2.bn1.bias\n",
      "model.layer2.2.conv2.weight\n",
      "model.layer2.2.bn2.weight\n",
      "model.layer2.2.bn2.bias\n",
      "model.layer2.2.conv3.weight\n",
      "model.layer2.2.bn3.weight\n",
      "model.layer2.2.bn3.bias\n",
      "model.layer2.3.conv1.weight\n",
      "model.layer2.3.bn1.weight\n",
      "model.layer2.3.bn1.bias\n",
      "model.layer2.3.conv2.weight\n",
      "model.layer2.3.bn2.weight\n",
      "model.layer2.3.bn2.bias\n",
      "model.layer2.3.conv3.weight\n",
      "model.layer2.3.bn3.weight\n",
      "model.layer2.3.bn3.bias\n",
      "model.layer3.0.conv1.weight\n",
      "model.layer3.0.bn1.weight\n",
      "model.layer3.0.bn1.bias\n",
      "model.layer3.0.conv2.weight\n",
      "model.layer3.0.bn2.weight\n",
      "model.layer3.0.bn2.bias\n",
      "model.layer3.0.conv3.weight\n",
      "model.layer3.0.bn3.weight\n",
      "model.layer3.0.bn3.bias\n",
      "model.layer3.0.downsample.0.weight\n",
      "model.layer3.0.downsample.1.weight\n",
      "model.layer3.0.downsample.1.bias\n",
      "model.layer3.1.conv1.weight\n",
      "model.layer3.1.bn1.weight\n",
      "model.layer3.1.bn1.bias\n",
      "model.layer3.1.conv2.weight\n",
      "model.layer3.1.bn2.weight\n",
      "model.layer3.1.bn2.bias\n",
      "model.layer3.1.conv3.weight\n",
      "model.layer3.1.bn3.weight\n",
      "model.layer3.1.bn3.bias\n",
      "model.layer3.2.conv1.weight\n",
      "model.layer3.2.bn1.weight\n",
      "model.layer3.2.bn1.bias\n",
      "model.layer3.2.conv2.weight\n",
      "model.layer3.2.bn2.weight\n",
      "model.layer3.2.bn2.bias\n",
      "model.layer3.2.conv3.weight\n",
      "model.layer3.2.bn3.weight\n",
      "model.layer3.2.bn3.bias\n",
      "model.layer3.3.conv1.weight\n",
      "model.layer3.3.bn1.weight\n",
      "model.layer3.3.bn1.bias\n",
      "model.layer3.3.conv2.weight\n",
      "model.layer3.3.bn2.weight\n",
      "model.layer3.3.bn2.bias\n",
      "model.layer3.3.conv3.weight\n",
      "model.layer3.3.bn3.weight\n",
      "model.layer3.3.bn3.bias\n",
      "model.layer3.4.conv1.weight\n",
      "model.layer3.4.bn1.weight\n",
      "model.layer3.4.bn1.bias\n",
      "model.layer3.4.conv2.weight\n",
      "model.layer3.4.bn2.weight\n",
      "model.layer3.4.bn2.bias\n",
      "model.layer3.4.conv3.weight\n",
      "model.layer3.4.bn3.weight\n",
      "model.layer3.4.bn3.bias\n",
      "model.layer3.5.conv1.weight\n",
      "model.layer3.5.bn1.weight\n",
      "model.layer3.5.bn1.bias\n",
      "model.layer3.5.conv2.weight\n",
      "model.layer3.5.bn2.weight\n",
      "model.layer3.5.bn2.bias\n",
      "model.layer3.5.conv3.weight\n",
      "model.layer3.5.bn3.weight\n",
      "model.layer3.5.bn3.bias\n",
      "model.layer4.0.conv1.weight\n",
      "model.layer4.0.bn1.weight\n",
      "model.layer4.0.bn1.bias\n",
      "model.layer4.0.conv2.weight\n",
      "model.layer4.0.bn2.weight\n",
      "model.layer4.0.bn2.bias\n",
      "model.layer4.0.conv3.weight\n",
      "model.layer4.0.bn3.weight\n",
      "model.layer4.0.bn3.bias\n",
      "model.layer4.0.downsample.0.weight\n",
      "model.layer4.0.downsample.1.weight\n",
      "model.layer4.0.downsample.1.bias\n",
      "model.layer4.1.conv1.weight\n",
      "model.layer4.1.bn1.weight\n",
      "model.layer4.1.bn1.bias\n",
      "model.layer4.1.conv2.weight\n",
      "model.layer4.1.bn2.weight\n",
      "model.layer4.1.bn2.bias\n",
      "model.layer4.1.conv3.weight\n",
      "model.layer4.1.bn3.weight\n",
      "model.layer4.1.bn3.bias\n",
      "model.layer4.2.conv1.weight\n",
      "model.layer4.2.bn1.weight\n",
      "model.layer4.2.bn1.bias\n",
      "model.layer4.2.conv2.weight\n",
      "model.layer4.2.bn2.weight\n",
      "model.layer4.2.bn2.bias\n",
      "model.layer4.2.conv3.weight\n",
      "model.layer4.2.bn3.weight\n",
      "model.layer4.2.bn3.bias\n",
      "model.last_linear.weight\n",
      "model.last_linear.bias\n",
      "l0.weight\n",
      "l0.bias\n",
      "l1.weight\n",
      "l1.bias\n",
      "l2.weight\n",
      "l2.bias\n",
      "l3.weight\n",
      "l3.bias\n",
      "l4.weight\n",
      "l4.bias\n",
      "l5.weight\n",
      "l5.bias\n",
      "l6.weight\n",
      "l6.bias\n",
      "l7.weight\n",
      "l7.bias\n",
      "l8.weight\n",
      "l8.bias\n",
      "l9.weight\n",
      "l9.bias\n",
      "l10.weight\n",
      "l10.bias\n",
      "l11.weight\n",
      "l11.bias\n",
      "l12.weight\n",
      "l12.bias\n",
      "l13.weight\n",
      "l13.bias\n",
      "l14.weight\n",
      "l14.bias\n",
      "l15.weight\n",
      "l15.bias\n",
      "l16.weight\n",
      "l16.bias\n",
      "l17.weight\n",
      "l17.bias\n",
      "l18.weight\n",
      "l18.bias\n",
      "l19.weight\n",
      "l19.bias\n",
      "l20.weight\n",
      "l20.bias\n",
      "l21.weight\n",
      "l21.bias\n",
      "l22.weight\n",
      "l22.bias\n",
      "l23.weight\n",
      "l23.bias\n",
      "l24.weight\n",
      "l24.bias\n",
      "l25.weight\n",
      "l25.bias\n",
      "l26.weight\n",
      "l26.bias\n",
      "l27.weight\n",
      "l27.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        #print(dir(param))\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_groups = [\n",
    "    [model.model.conv1, model.model.bn1, model.model.layer1, model.model.layer2],\n",
    "    [model.model.layer3, model.model.layer4],\n",
    "    [model.model.last_linear]\n",
    "]\n",
    "\n",
    "lrs = np.array([lr / 10, lr / 3, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__^ This is how our custom model can use the differential learning rate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b20f45c692c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m optim.SGD([\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             ], lr=1e-2, momentum=0.9)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'base'"
     ]
    }
   ],
   "source": [
    "# Another example from torch.optim documentation\n",
    "import torch.optim as optim\n",
    "\n",
    "model = ResNet50(pretrained='imagenet').model\n",
    "\n",
    "optim.SGD([\n",
    "                {'params': model.base.parameters()},\n",
    "                {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "            ], lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would be equivalent to freezing all layers\n",
    "# for param in model.features.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test if freeze/unfreeze it working\n",
    "model = ResNet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight\n",
      "model.bn1.weight\n",
      "model.bn1.bias\n",
      "model.layer1.0.conv1.weight\n",
      "model.layer1.0.bn1.weight\n",
      "model.layer1.0.bn1.bias\n",
      "model.layer1.0.conv2.weight\n",
      "model.layer1.0.bn2.weight\n",
      "model.layer1.0.bn2.bias\n",
      "model.layer1.0.conv3.weight\n",
      "model.layer1.0.bn3.weight\n",
      "model.layer1.0.bn3.bias\n",
      "model.layer1.0.downsample.0.weight\n",
      "model.layer1.0.downsample.1.weight\n",
      "model.layer1.0.downsample.1.bias\n",
      "model.layer1.1.conv1.weight\n",
      "model.layer1.1.bn1.weight\n",
      "model.layer1.1.bn1.bias\n",
      "model.layer1.1.conv2.weight\n",
      "model.layer1.1.bn2.weight\n",
      "model.layer1.1.bn2.bias\n",
      "model.layer1.1.conv3.weight\n",
      "model.layer1.1.bn3.weight\n",
      "model.layer1.1.bn3.bias\n",
      "model.layer1.2.conv1.weight\n",
      "model.layer1.2.bn1.weight\n",
      "model.layer1.2.bn1.bias\n",
      "model.layer1.2.conv2.weight\n",
      "model.layer1.2.bn2.weight\n",
      "model.layer1.2.bn2.bias\n",
      "model.layer1.2.conv3.weight\n",
      "model.layer1.2.bn3.weight\n",
      "model.layer1.2.bn3.bias\n",
      "model.layer2.0.conv1.weight\n",
      "model.layer2.0.bn1.weight\n",
      "model.layer2.0.bn1.bias\n",
      "model.layer2.0.conv2.weight\n",
      "model.layer2.0.bn2.weight\n",
      "model.layer2.0.bn2.bias\n",
      "model.layer2.0.conv3.weight\n",
      "model.layer2.0.bn3.weight\n",
      "model.layer2.0.bn3.bias\n",
      "model.layer2.0.downsample.0.weight\n",
      "model.layer2.0.downsample.1.weight\n",
      "model.layer2.0.downsample.1.bias\n",
      "model.layer2.1.conv1.weight\n",
      "model.layer2.1.bn1.weight\n",
      "model.layer2.1.bn1.bias\n",
      "model.layer2.1.conv2.weight\n",
      "model.layer2.1.bn2.weight\n",
      "model.layer2.1.bn2.bias\n",
      "model.layer2.1.conv3.weight\n",
      "model.layer2.1.bn3.weight\n",
      "model.layer2.1.bn3.bias\n",
      "model.layer2.2.conv1.weight\n",
      "model.layer2.2.bn1.weight\n",
      "model.layer2.2.bn1.bias\n",
      "model.layer2.2.conv2.weight\n",
      "model.layer2.2.bn2.weight\n",
      "model.layer2.2.bn2.bias\n",
      "model.layer2.2.conv3.weight\n",
      "model.layer2.2.bn3.weight\n",
      "model.layer2.2.bn3.bias\n",
      "model.layer2.3.conv1.weight\n",
      "model.layer2.3.bn1.weight\n",
      "model.layer2.3.bn1.bias\n",
      "model.layer2.3.conv2.weight\n",
      "model.layer2.3.bn2.weight\n",
      "model.layer2.3.bn2.bias\n",
      "model.layer2.3.conv3.weight\n",
      "model.layer2.3.bn3.weight\n",
      "model.layer2.3.bn3.bias\n",
      "model.layer3.0.conv1.weight\n",
      "model.layer3.0.bn1.weight\n",
      "model.layer3.0.bn1.bias\n",
      "model.layer3.0.conv2.weight\n",
      "model.layer3.0.bn2.weight\n",
      "model.layer3.0.bn2.bias\n",
      "model.layer3.0.conv3.weight\n",
      "model.layer3.0.bn3.weight\n",
      "model.layer3.0.bn3.bias\n",
      "model.layer3.0.downsample.0.weight\n",
      "model.layer3.0.downsample.1.weight\n",
      "model.layer3.0.downsample.1.bias\n",
      "model.layer3.1.conv1.weight\n",
      "model.layer3.1.bn1.weight\n",
      "model.layer3.1.bn1.bias\n",
      "model.layer3.1.conv2.weight\n",
      "model.layer3.1.bn2.weight\n",
      "model.layer3.1.bn2.bias\n",
      "model.layer3.1.conv3.weight\n",
      "model.layer3.1.bn3.weight\n",
      "model.layer3.1.bn3.bias\n",
      "model.layer3.2.conv1.weight\n",
      "model.layer3.2.bn1.weight\n",
      "model.layer3.2.bn1.bias\n",
      "model.layer3.2.conv2.weight\n",
      "model.layer3.2.bn2.weight\n",
      "model.layer3.2.bn2.bias\n",
      "model.layer3.2.conv3.weight\n",
      "model.layer3.2.bn3.weight\n",
      "model.layer3.2.bn3.bias\n",
      "model.layer3.3.conv1.weight\n",
      "model.layer3.3.bn1.weight\n",
      "model.layer3.3.bn1.bias\n",
      "model.layer3.3.conv2.weight\n",
      "model.layer3.3.bn2.weight\n",
      "model.layer3.3.bn2.bias\n",
      "model.layer3.3.conv3.weight\n",
      "model.layer3.3.bn3.weight\n",
      "model.layer3.3.bn3.bias\n",
      "model.layer3.4.conv1.weight\n",
      "model.layer3.4.bn1.weight\n",
      "model.layer3.4.bn1.bias\n",
      "model.layer3.4.conv2.weight\n",
      "model.layer3.4.bn2.weight\n",
      "model.layer3.4.bn2.bias\n",
      "model.layer3.4.conv3.weight\n",
      "model.layer3.4.bn3.weight\n",
      "model.layer3.4.bn3.bias\n",
      "model.layer3.5.conv1.weight\n",
      "model.layer3.5.bn1.weight\n",
      "model.layer3.5.bn1.bias\n",
      "model.layer3.5.conv2.weight\n",
      "model.layer3.5.bn2.weight\n",
      "model.layer3.5.bn2.bias\n",
      "model.layer3.5.conv3.weight\n",
      "model.layer3.5.bn3.weight\n",
      "model.layer3.5.bn3.bias\n",
      "model.layer4.0.conv1.weight\n",
      "model.layer4.0.bn1.weight\n",
      "model.layer4.0.bn1.bias\n",
      "model.layer4.0.conv2.weight\n",
      "model.layer4.0.bn2.weight\n",
      "model.layer4.0.bn2.bias\n",
      "model.layer4.0.conv3.weight\n",
      "model.layer4.0.bn3.weight\n",
      "model.layer4.0.bn3.bias\n",
      "model.layer4.0.downsample.0.weight\n",
      "model.layer4.0.downsample.1.weight\n",
      "model.layer4.0.downsample.1.bias\n",
      "model.layer4.1.conv1.weight\n",
      "model.layer4.1.bn1.weight\n",
      "model.layer4.1.bn1.bias\n",
      "model.layer4.1.conv2.weight\n",
      "model.layer4.1.bn2.weight\n",
      "model.layer4.1.bn2.bias\n",
      "model.layer4.1.conv3.weight\n",
      "model.layer4.1.bn3.weight\n",
      "model.layer4.1.bn3.bias\n",
      "model.layer4.2.conv1.weight\n",
      "model.layer4.2.bn1.weight\n",
      "model.layer4.2.bn1.bias\n",
      "model.layer4.2.conv2.weight\n",
      "model.layer4.2.bn2.weight\n",
      "model.layer4.2.bn2.bias\n",
      "model.layer4.2.conv3.weight\n",
      "model.layer4.2.bn3.weight\n",
      "model.layer4.2.bn3.bias\n",
      "model.last_linear.weight\n",
      "model.last_linear.bias\n",
      "l0.weight\n",
      "l0.bias\n",
      "l1.weight\n",
      "l1.bias\n",
      "l2.weight\n",
      "l2.bias\n",
      "l3.weight\n",
      "l3.bias\n",
      "l4.weight\n",
      "l4.bias\n",
      "l5.weight\n",
      "l5.bias\n",
      "l6.weight\n",
      "l6.bias\n",
      "l7.weight\n",
      "l7.bias\n",
      "l8.weight\n",
      "l8.bias\n",
      "l9.weight\n",
      "l9.bias\n",
      "l10.weight\n",
      "l10.bias\n",
      "l11.weight\n",
      "l11.bias\n",
      "l12.weight\n",
      "l12.bias\n",
      "l13.weight\n",
      "l13.bias\n",
      "l14.weight\n",
      "l14.bias\n",
      "l15.weight\n",
      "l15.bias\n",
      "l16.weight\n",
      "l16.bias\n",
      "l17.weight\n",
      "l17.bias\n",
      "l18.weight\n",
      "l18.bias\n",
      "l19.weight\n",
      "l19.bias\n",
      "l20.weight\n",
      "l20.bias\n",
      "l21.weight\n",
      "l21.bias\n",
      "l22.weight\n",
      "l22.bias\n",
      "l23.weight\n",
      "l23.bias\n",
      "l24.weight\n",
      "l24.bias\n",
      "l25.weight\n",
      "l25.bias\n",
      "l26.weight\n",
      "l26.bias\n",
      "l27.weight\n",
      "l27.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ as expected this prints nothing because all layer are frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight\n",
      "model.bn1.weight\n",
      "model.bn1.bias\n",
      "model.layer1.0.conv1.weight\n",
      "model.layer1.0.bn1.weight\n",
      "model.layer1.0.bn1.bias\n",
      "model.layer1.0.conv2.weight\n",
      "model.layer1.0.bn2.weight\n",
      "model.layer1.0.bn2.bias\n",
      "model.layer1.0.conv3.weight\n",
      "model.layer1.0.bn3.weight\n",
      "model.layer1.0.bn3.bias\n",
      "model.layer1.0.downsample.0.weight\n",
      "model.layer1.0.downsample.1.weight\n",
      "model.layer1.0.downsample.1.bias\n",
      "model.layer1.1.conv1.weight\n",
      "model.layer1.1.bn1.weight\n",
      "model.layer1.1.bn1.bias\n",
      "model.layer1.1.conv2.weight\n",
      "model.layer1.1.bn2.weight\n",
      "model.layer1.1.bn2.bias\n",
      "model.layer1.1.conv3.weight\n",
      "model.layer1.1.bn3.weight\n",
      "model.layer1.1.bn3.bias\n",
      "model.layer1.2.conv1.weight\n",
      "model.layer1.2.bn1.weight\n",
      "model.layer1.2.bn1.bias\n",
      "model.layer1.2.conv2.weight\n",
      "model.layer1.2.bn2.weight\n",
      "model.layer1.2.bn2.bias\n",
      "model.layer1.2.conv3.weight\n",
      "model.layer1.2.bn3.weight\n",
      "model.layer1.2.bn3.bias\n",
      "model.layer2.0.conv1.weight\n",
      "model.layer2.0.bn1.weight\n",
      "model.layer2.0.bn1.bias\n",
      "model.layer2.0.conv2.weight\n",
      "model.layer2.0.bn2.weight\n",
      "model.layer2.0.bn2.bias\n",
      "model.layer2.0.conv3.weight\n",
      "model.layer2.0.bn3.weight\n",
      "model.layer2.0.bn3.bias\n",
      "model.layer2.0.downsample.0.weight\n",
      "model.layer2.0.downsample.1.weight\n",
      "model.layer2.0.downsample.1.bias\n",
      "model.layer2.1.conv1.weight\n",
      "model.layer2.1.bn1.weight\n",
      "model.layer2.1.bn1.bias\n",
      "model.layer2.1.conv2.weight\n",
      "model.layer2.1.bn2.weight\n",
      "model.layer2.1.bn2.bias\n",
      "model.layer2.1.conv3.weight\n",
      "model.layer2.1.bn3.weight\n",
      "model.layer2.1.bn3.bias\n",
      "model.layer2.2.conv1.weight\n",
      "model.layer2.2.bn1.weight\n",
      "model.layer2.2.bn1.bias\n",
      "model.layer2.2.conv2.weight\n",
      "model.layer2.2.bn2.weight\n",
      "model.layer2.2.bn2.bias\n",
      "model.layer2.2.conv3.weight\n",
      "model.layer2.2.bn3.weight\n",
      "model.layer2.2.bn3.bias\n",
      "model.layer2.3.conv1.weight\n",
      "model.layer2.3.bn1.weight\n",
      "model.layer2.3.bn1.bias\n",
      "model.layer2.3.conv2.weight\n",
      "model.layer2.3.bn2.weight\n",
      "model.layer2.3.bn2.bias\n",
      "model.layer2.3.conv3.weight\n",
      "model.layer2.3.bn3.weight\n",
      "model.layer2.3.bn3.bias\n",
      "model.layer3.0.conv1.weight\n",
      "model.layer3.0.bn1.weight\n",
      "model.layer3.0.bn1.bias\n",
      "model.layer3.0.conv2.weight\n",
      "model.layer3.0.bn2.weight\n",
      "model.layer3.0.bn2.bias\n",
      "model.layer3.0.conv3.weight\n",
      "model.layer3.0.bn3.weight\n",
      "model.layer3.0.bn3.bias\n",
      "model.layer3.0.downsample.0.weight\n",
      "model.layer3.0.downsample.1.weight\n",
      "model.layer3.0.downsample.1.bias\n",
      "model.layer3.1.conv1.weight\n",
      "model.layer3.1.bn1.weight\n",
      "model.layer3.1.bn1.bias\n",
      "model.layer3.1.conv2.weight\n",
      "model.layer3.1.bn2.weight\n",
      "model.layer3.1.bn2.bias\n",
      "model.layer3.1.conv3.weight\n",
      "model.layer3.1.bn3.weight\n",
      "model.layer3.1.bn3.bias\n",
      "model.layer3.2.conv1.weight\n",
      "model.layer3.2.bn1.weight\n",
      "model.layer3.2.bn1.bias\n",
      "model.layer3.2.conv2.weight\n",
      "model.layer3.2.bn2.weight\n",
      "model.layer3.2.bn2.bias\n",
      "model.layer3.2.conv3.weight\n",
      "model.layer3.2.bn3.weight\n",
      "model.layer3.2.bn3.bias\n",
      "model.layer3.3.conv1.weight\n",
      "model.layer3.3.bn1.weight\n",
      "model.layer3.3.bn1.bias\n",
      "model.layer3.3.conv2.weight\n",
      "model.layer3.3.bn2.weight\n",
      "model.layer3.3.bn2.bias\n",
      "model.layer3.3.conv3.weight\n",
      "model.layer3.3.bn3.weight\n",
      "model.layer3.3.bn3.bias\n",
      "model.layer3.4.conv1.weight\n",
      "model.layer3.4.bn1.weight\n",
      "model.layer3.4.bn1.bias\n",
      "model.layer3.4.conv2.weight\n",
      "model.layer3.4.bn2.weight\n",
      "model.layer3.4.bn2.bias\n",
      "model.layer3.4.conv3.weight\n",
      "model.layer3.4.bn3.weight\n",
      "model.layer3.4.bn3.bias\n",
      "model.layer3.5.conv1.weight\n",
      "model.layer3.5.bn1.weight\n",
      "model.layer3.5.bn1.bias\n",
      "model.layer3.5.conv2.weight\n",
      "model.layer3.5.bn2.weight\n",
      "model.layer3.5.bn2.bias\n",
      "model.layer3.5.conv3.weight\n",
      "model.layer3.5.bn3.weight\n",
      "model.layer3.5.bn3.bias\n",
      "model.layer4.0.conv1.weight\n",
      "model.layer4.0.bn1.weight\n",
      "model.layer4.0.bn1.bias\n",
      "model.layer4.0.conv2.weight\n",
      "model.layer4.0.bn2.weight\n",
      "model.layer4.0.bn2.bias\n",
      "model.layer4.0.conv3.weight\n",
      "model.layer4.0.bn3.weight\n",
      "model.layer4.0.bn3.bias\n",
      "model.layer4.0.downsample.0.weight\n",
      "model.layer4.0.downsample.1.weight\n",
      "model.layer4.0.downsample.1.bias\n",
      "model.layer4.1.conv1.weight\n",
      "model.layer4.1.bn1.weight\n",
      "model.layer4.1.bn1.bias\n",
      "model.layer4.1.conv2.weight\n",
      "model.layer4.1.bn2.weight\n",
      "model.layer4.1.bn2.bias\n",
      "model.layer4.1.conv3.weight\n",
      "model.layer4.1.bn3.weight\n",
      "model.layer4.1.bn3.bias\n",
      "model.layer4.2.conv1.weight\n",
      "model.layer4.2.bn1.weight\n",
      "model.layer4.2.bn1.bias\n",
      "model.layer4.2.conv2.weight\n",
      "model.layer4.2.bn2.weight\n",
      "model.layer4.2.bn2.bias\n",
      "model.layer4.2.conv3.weight\n",
      "model.layer4.2.bn3.weight\n",
      "model.layer4.2.bn3.bias\n",
      "model.last_linear.weight\n",
      "model.last_linear.bias\n",
      "l0.weight\n",
      "l0.bias\n",
      "l1.weight\n",
      "l1.bias\n",
      "l2.weight\n",
      "l2.bias\n",
      "l3.weight\n",
      "l3.bias\n",
      "l4.weight\n",
      "l4.bias\n",
      "l5.weight\n",
      "l5.bias\n",
      "l6.weight\n",
      "l6.bias\n",
      "l7.weight\n",
      "l7.bias\n",
      "l8.weight\n",
      "l8.bias\n",
      "l9.weight\n",
      "l9.bias\n",
      "l10.weight\n",
      "l10.bias\n",
      "l11.weight\n",
      "l11.bias\n",
      "l12.weight\n",
      "l12.bias\n",
      "l13.weight\n",
      "l13.bias\n",
      "l14.weight\n",
      "l14.bias\n",
      "l15.weight\n",
      "l15.bias\n",
      "l16.weight\n",
      "l16.bias\n",
      "l17.weight\n",
      "l17.bias\n",
      "l18.weight\n",
      "l18.bias\n",
      "l19.weight\n",
      "l19.bias\n",
      "l20.weight\n",
      "l20.bias\n",
      "l21.weight\n",
      "l21.bias\n",
      "l22.weight\n",
      "l22.bias\n",
      "l23.weight\n",
      "l23.bias\n",
      "l24.weight\n",
      "l24.bias\n",
      "l25.weight\n",
      "l25.bias\n",
      "l26.weight\n",
      "l26.bias\n",
      "l27.weight\n",
      "l27.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ as expected this prints everything because all layer are unfrozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write freeze_to in the next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for param in model.parameters():\n",
    "    counter += 1\n",
    "    \n",
    "print(counter)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        counter += 1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 7, 7])\n",
      "bn1.weight torch.Size([64])\n",
      "bn1.bias torch.Size([64])\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight torch.Size([256])\n",
      "layer1.0.bn3.bias torch.Size([256])\n",
      "layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight torch.Size([256])\n",
      "layer1.0.downsample.1.bias torch.Size([256])\n",
      "layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight torch.Size([256])\n",
      "layer1.1.bn3.bias torch.Size([256])\n",
      "layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight torch.Size([64])\n",
      "layer1.2.bn1.bias torch.Size([64])\n",
      "layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight torch.Size([64])\n",
      "layer1.2.bn2.bias torch.Size([64])\n",
      "layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight torch.Size([256])\n",
      "layer1.2.bn3.bias torch.Size([256])\n",
      "layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight torch.Size([512])\n",
      "layer2.0.bn3.bias torch.Size([512])\n",
      "layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight torch.Size([512])\n",
      "layer2.0.downsample.1.bias torch.Size([512])\n",
      "layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight torch.Size([512])\n",
      "layer2.1.bn3.bias torch.Size([512])\n",
      "layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight torch.Size([128])\n",
      "layer2.2.bn1.bias torch.Size([128])\n",
      "layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight torch.Size([128])\n",
      "layer2.2.bn2.bias torch.Size([128])\n",
      "layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight torch.Size([512])\n",
      "layer2.2.bn3.bias torch.Size([512])\n",
      "layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight torch.Size([128])\n",
      "layer2.3.bn1.bias torch.Size([128])\n",
      "layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight torch.Size([128])\n",
      "layer2.3.bn2.bias torch.Size([128])\n",
      "layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight torch.Size([512])\n",
      "layer2.3.bn3.bias torch.Size([512])\n",
      "layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight torch.Size([1024])\n",
      "layer3.0.bn3.bias torch.Size([1024])\n",
      "layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight torch.Size([1024])\n",
      "layer3.0.downsample.1.bias torch.Size([1024])\n",
      "layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight torch.Size([1024])\n",
      "layer3.1.bn3.bias torch.Size([1024])\n",
      "layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight torch.Size([256])\n",
      "layer3.2.bn1.bias torch.Size([256])\n",
      "layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight torch.Size([256])\n",
      "layer3.2.bn2.bias torch.Size([256])\n",
      "layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight torch.Size([1024])\n",
      "layer3.2.bn3.bias torch.Size([1024])\n",
      "layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight torch.Size([256])\n",
      "layer3.3.bn1.bias torch.Size([256])\n",
      "layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight torch.Size([256])\n",
      "layer3.3.bn2.bias torch.Size([256])\n",
      "layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight torch.Size([1024])\n",
      "layer3.3.bn3.bias torch.Size([1024])\n",
      "layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight torch.Size([256])\n",
      "layer3.4.bn1.bias torch.Size([256])\n",
      "layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight torch.Size([256])\n",
      "layer3.4.bn2.bias torch.Size([256])\n",
      "layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight torch.Size([1024])\n",
      "layer3.4.bn3.bias torch.Size([1024])\n",
      "layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight torch.Size([256])\n",
      "layer3.5.bn1.bias torch.Size([256])\n",
      "layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight torch.Size([256])\n",
      "layer3.5.bn2.bias torch.Size([256])\n",
      "layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight torch.Size([1024])\n",
      "layer3.5.bn3.bias torch.Size([1024])\n",
      "layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight torch.Size([2048])\n",
      "layer4.0.bn3.bias torch.Size([2048])\n",
      "layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight torch.Size([2048])\n",
      "layer4.0.downsample.1.bias torch.Size([2048])\n",
      "layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight torch.Size([2048])\n",
      "layer4.1.bn3.bias torch.Size([2048])\n",
      "layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight torch.Size([512])\n",
      "layer4.2.bn1.bias torch.Size([512])\n",
      "layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight torch.Size([512])\n",
      "layer4.2.bn2.bias torch.Size([512])\n",
      "layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight torch.Size([2048])\n",
      "layer4.2.bn3.bias torch.Size([2048])\n",
      "last_linear.weight torch.Size([1000, 2048])\n",
      "last_linear.bias torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(pretrained=True).model\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "       AvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.cuda(),(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
