{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this note bookbook, we will create and save images by reading parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# If we don't do this then image will open as pop-up and not in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 1.14.0\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /home/ubuntu/.local/lib/python3.6/site-packages\r\n",
      "Requires: six, astor, keras-applications, keras-preprocessing, numpy, wrapt, grpcio, tensorflow-estimator, absl-py, wheel, termcolor, google-pasta, gast, tensorboard, protobuf\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTHONPATH=/home/ubuntu/.local/lib/python3.6/site-packages:$PYTHONPATH.\n",
    "# ^ This makes all other libraries inaccessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2951M\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu    1M Jan 28 21:05 cv10_data\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu    1M Sep 30 23:37 cv10_labels.npy\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 2951M Jan 28 20:52 ddsm-mammography.zip\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu    1M Jan 28 21:05 test10_data\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu    1M Sep 30 23:38 test10_labels.npy\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu    1M Jan 28 21:05 training10_0\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu    1M Jan 28 21:05 training10_1\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu    1M Jan 28 21:05 training10_2\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu    1M Jan 28 21:05 training10_3\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu    1M Jan 28 21:05 training10_4\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l --block=M /home/ubuntu/datasets/mammography/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As tensorflow could not be loaded we are going to use tfrecord library:\n",
    "https://github.com/vahidk/tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure everything was written properly by reading it back out\n",
    "def read_and_decode_single_example(filenames):\n",
    "    filename_queue = tf.train.string_input_producer(filenames, num_epochs=1)\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    \n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'label_normal': tf.FixedLenFeature([], tf.int64),\n",
    "            'image': tf.FixedLenFeature([], tf.string)\n",
    "        })\n",
    "    \n",
    "    # now return the converted data\n",
    "    label = features['label_normal']\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [299, 299, 1])\n",
    "    \n",
    "    return label, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a2bd6221959f>:3: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:113: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:2322: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-8-a2bd6221959f>:5: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-9-44bd11fec216>:2: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "label, image = read_and_decode_single_example([\"~/datasets/mammography/training10_0/training10_0.tfrecords\", \"~/datasets/mammography/training10_1/training10_1.tfrecords\"])\n",
    "images_batch, labels_batch = tf.train.batch([image, label], batch_size=16, capacity=2000)\n",
    "global_step = tf.Variable(0, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'batch:1' shape=(16,) dtype=int64>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch.get_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_resized(dataframe, n):\n",
    "    img_name = dataframe.iloc[n, 0]\n",
    "    img_data = np.array(dataframe.iloc[n, 1:])\n",
    "    img_data = img_data.astype('float').reshape(137,236)\n",
    "    #img_data = im.resize img_data\n",
    "    img_data = cv2.resize(img_data, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "    # normalizing the image\n",
    "    img_data = (img_data*(255.0/img_data.max())).astype(np.uint8)\n",
    "    # show\n",
    "    imshow(img_data, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image_resized(train, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and converting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = pq.read_pandas('/home/ubuntu/datasets/bengali-ai/train_image_data_0.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = train_0\n",
    "\n",
    "for row in range(len(dataframe)):\n",
    "    img_name = dataframe.iloc[row, 0]\n",
    "    img_data = np.array(dataframe.iloc[row, 1:])\n",
    "    img_data = img_data.astype('float').reshape(137,236)\n",
    "    img_data = cv2.resize(img_data, dsize=(img_dim, img_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    # normalizing the image\n",
    "    img_data = (img_data*(255.0/img_data.max())).astype(np.uint8)\n",
    "    # save\n",
    "    plt.image.imsave('/home/ubuntu/datasets/bengali-ai/training_images/train_0/'+img_name+'.png', img_data, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pq.read_pandas('/home/ubuntu/datasets/bengali-ai/train_image_data_1.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = train_1\n",
    "\n",
    "for row in range(len(dataframe)):\n",
    "    img_name = dataframe.iloc[row, 0]\n",
    "    img_data = np.array(dataframe.iloc[row, 1:])\n",
    "    img_data = img_data.astype('float').reshape(137,236)\n",
    "    img_data = cv2.resize(img_data, dsize=(img_dim, img_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    # normalizing the image\n",
    "    img_data = (img_data*(255.0/img_data.max())).astype(np.uint8)\n",
    "    # save\n",
    "    plt.image.imsave('/home/ubuntu/datasets/bengali-ai/training_images/train_1/'+img_name+'.png', img_data, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_0 = pq.read_pandas('/home/ubuntu/datasets/bengali-ai/test_image_data_0.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = test_0\n",
    "\n",
    "for row in range(len(dataframe)):\n",
    "    img_name = dataframe.iloc[row, 0]\n",
    "    img_data = np.array(dataframe.iloc[row, 1:])\n",
    "    img_data = img_data.astype('float').reshape(137,236)\n",
    "    img_data = cv2.resize(img_data, dsize=(img_dim, img_dim), interpolation=cv2.INTER_CUBIC)\n",
    "    # normalizing the image\n",
    "    img_data = (img_data*(255.0/img_data.max())).astype(np.uint8)\n",
    "    # save\n",
    "    plt.image.imsave('/home/ubuntu/datasets/bengali-ai/testing_images/test_0/'+img_name+'.png', img_data, cmap='gray')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
